{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.023553,
     "end_time": "2022-08-15T20:13:53.578530",
     "exception": false,
     "start_time": "2022-08-15T20:13:53.554977",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Natural Language Processing Project: Japanese ML Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.021906,
     "end_time": "2022-08-15T20:13:53.621070",
     "exception": false,
     "start_time": "2022-08-15T20:13:53.599164",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Coded by Luna McBride\n",
    "\n",
    "The point of this notebook is to test Japanese language processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.019559,
     "end_time": "2022-08-15T20:13:53.660822",
     "exception": false,
     "start_time": "2022-08-15T20:13:53.641263",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# test linking to github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-15T20:13:53.703908Z",
     "iopub.status.busy": "2022-08-15T20:13:53.703242Z",
     "iopub.status.idle": "2022-08-15T20:16:58.226910Z",
     "shell.execute_reply": "2022-08-15T20:16:58.225858Z",
     "shell.execute_reply.started": "2022-08-12T21:41:42.989000Z"
    },
    "papermill": {
     "duration": 184.546277,
     "end_time": "2022-08-15T20:16:58.227139",
     "exception": false,
     "start_time": "2022-08-15T20:13:53.680862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ja_core_news_lg==2.3.2\r\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/ja_core_news_lg-2.3.2/ja_core_news_lg-2.3.2.tar.gz (552.0 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 552.0 MB 1.2 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: spacy<2.4.0,>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from ja_core_news_lg==2.3.2) (2.3.2)\r\n",
      "Collecting sudachipy>=0.4.5\r\n",
      "  Downloading SudachiPy-0.6.6-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.2 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 575 kB/s \r\n",
      "\u001b[?25hCollecting sudachidict_core>=20200330\r\n",
      "  Downloading SudachiDict-core-20220729.tar.gz (9.1 kB)\r\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->ja_core_news_lg==2.3.2) (1.18.5)\r\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->ja_core_news_lg==2.3.2) (0.8.0)\r\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->ja_core_news_lg==2.3.2) (1.0.2)\r\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->ja_core_news_lg==2.3.2) (1.0.0)\r\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->ja_core_news_lg==2.3.2) (2.0.3)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->ja_core_news_lg==2.3.2) (4.45.0)\r\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->ja_core_news_lg==2.3.2) (3.0.2)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->ja_core_news_lg==2.3.2) (46.1.3.post20200325)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->ja_core_news_lg==2.3.2) (2.23.0)\r\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->ja_core_news_lg==2.3.2) (1.1.3)\r\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->ja_core_news_lg==2.3.2) (0.4.1)\r\n",
      "Requirement already satisfied: thinc==7.4.1 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->ja_core_news_lg==2.3.2) (7.4.1)\r\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->ja_core_news_lg==2.3.2) (1.0.2)\r\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->ja_core_news_lg==2.3.2) (1.6.0)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->ja_core_news_lg==2.3.2) (2.9)\r\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->ja_core_news_lg==2.3.2) (3.0.4)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->ja_core_news_lg==2.3.2) (2020.6.20)\r\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->ja_core_news_lg==2.3.2) (1.24.3)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->ja_core_news_lg==2.3.2) (3.1.0)\r\n",
      "Building wheels for collected packages: ja-core-news-lg, sudachidict-core\r\n",
      "  Building wheel for ja-core-news-lg (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for ja-core-news-lg: filename=ja_core_news_lg-2.3.2-py3-none-any.whl size=552165692 sha256=6629158a84fc4a9c400a7a607bc5b7cbe86b39ac94706c596b6749d8d0e85041\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-hiy3go0c/wheels/73/c9/4e/b4627ff7e525d768a5f403dfd3810a50b0a2a2efbd6a7e4647\r\n",
      "  Building wheel for sudachidict-core (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for sudachidict-core: filename=SudachiDict_core-20220729-py3-none-any.whl size=71570366 sha256=257c3102627494174dbe2796353032bcdabf8dcb753580f74cb8ad9416e57e00\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-hiy3go0c/wheels/ff/47/2b/6dcb905d9086fc6f9b7af821f7145f785d36070b827b7f80b7\r\n",
      "Successfully built ja-core-news-lg sudachidict-core\r\n",
      "Installing collected packages: sudachipy, sudachidict-core, ja-core-news-lg\r\n",
      "Successfully installed ja-core-news-lg-2.3.2 sudachidict-core-20220729 sudachipy-0.6.6\r\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 22.2.2 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\r\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\r\n",
      "You can now load the model via spacy.load('ja_core_news_lg')\r\n"
     ]
    }
   ],
   "source": [
    "import sys #Used exclusively to get ja_core_news_lg, which does not save between sessions\n",
    "!{sys.executable} -m spacy download ja_core_news_lg #Downloads ja_core_news_lg, which is used for spacy Japanese processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-08-15T20:16:59.219941Z",
     "iopub.status.busy": "2022-08-15T20:16:59.216523Z",
     "iopub.status.idle": "2022-08-15T20:17:01.990715Z",
     "shell.execute_reply": "2022-08-15T20:17:01.990087Z",
     "shell.execute_reply.started": "2022-08-12T21:44:11.158864Z"
    },
    "papermill": {
     "duration": 3.271391,
     "end_time": "2022-08-15T20:17:01.990850",
     "exception": false,
     "start_time": "2022-08-15T20:16:58.719459",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/ml-tweet/Twitter ML Data.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import re # regular expressions\n",
    "import html # HTML content, like &amp;\n",
    "\n",
    "import spacy #For general NLP\n",
    "from spacy.lang.ja.stop_words import STOP_WORDS #Get the Japanese stopwords\n",
    "\n",
    "import ja_core_news_lg #Japanese language handling\n",
    "nlp =  ja_core_news_lg.load() #Initializing Spacy for Japanese\n",
    "import operator #For dictionary sorting\n",
    "\n",
    "import matplotlib.pylab as plt #For plot testing\n",
    "%matplotlib inline\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.565975,
     "end_time": "2022-08-15T20:17:03.112206",
     "exception": false,
     "start_time": "2022-08-15T20:17:02.546231",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.479436,
     "end_time": "2022-08-15T20:17:04.074898",
     "exception": false,
     "start_time": "2022-08-15T20:17:03.595462",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-15T20:17:05.121349Z",
     "iopub.status.busy": "2022-08-15T20:17:05.120332Z",
     "iopub.status.idle": "2022-08-15T20:17:06.200324Z",
     "shell.execute_reply": "2022-08-15T20:17:06.201710Z",
     "shell.execute_reply.started": "2022-08-12T21:45:08.127845Z"
    },
    "papermill": {
     "duration": 1.563596,
     "end_time": "2022-08-15T20:17:06.201886",
     "exception": false,
     "start_time": "2022-08-15T20:17:04.638290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-15T20:17:07.223581Z",
     "iopub.status.busy": "2022-08-15T20:17:07.222810Z",
     "iopub.status.idle": "2022-08-15T20:17:08.282631Z",
     "shell.execute_reply": "2022-08-15T20:17:08.282031Z",
     "shell.execute_reply.started": "2022-08-12T21:46:46.136549Z"
    },
    "papermill": {
     "duration": 1.550656,
     "end_time": "2022-08-15T20:17:08.282780",
     "exception": false,
     "start_time": "2022-08-15T20:17:06.732124",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 0\r\n",
      "drwxr-xr-x 2 nobody nogroup 0 Aug 12 21:41 ml-tweet\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l ../input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2022-08-15T20:17:09.279373Z",
     "iopub.status.busy": "2022-08-15T20:17:09.278614Z",
     "iopub.status.idle": "2022-08-15T20:17:09.335399Z",
     "shell.execute_reply": "2022-08-15T20:17:09.335928Z",
     "shell.execute_reply.started": "2022-08-12T21:46:56.841230Z"
    },
    "papermill": {
     "duration": 0.550949,
     "end_time": "2022-08-15T20:17:09.336090",
     "exception": false,
     "start_time": "2022-08-15T20:17:08.785141",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aketaco</td>\n",
       "      <td>RT @odashi_t: 「機械学習がずるをしている（人間が想定しない推論を行う）から良く...</td>\n",
       "      <td>https://twitter.com/187400312/status/127142474...</td>\n",
       "      <td>Fri Jun 12 12:50:56 +0000 2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Atsunov</td>\n",
       "      <td>RT @ML_deep: y = f(x)\\n\\nというモデルで、ひと目では分からぬような関...</td>\n",
       "      <td>https://twitter.com/14404737/status/1271428080...</td>\n",
       "      <td>Fri Jun 12 13:04:10 +0000 2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name                                                  2  \\\n",
       "0      NaN                                                NaN   \n",
       "1      NaN                                                NaN   \n",
       "2      NaN                                                NaN   \n",
       "3  aketaco  RT @odashi_t: 「機械学習がずるをしている（人間が想定しない推論を行う）から良く...   \n",
       "4  Atsunov  RT @ML_deep: y = f(x)\\n\\nというモデルで、ひと目では分からぬような関...   \n",
       "\n",
       "                                                   3  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3  https://twitter.com/187400312/status/127142474...   \n",
       "4  https://twitter.com/14404737/status/1271428080...   \n",
       "\n",
       "                                4   5   6  \n",
       "0                             NaN NaN NaN  \n",
       "1                             NaN NaN NaN  \n",
       "2                             NaN NaN NaN  \n",
       "3  Fri Jun 12 12:50:56 +0000 2020 NaN NaN  \n",
       "4  Fri Jun 12 13:04:10 +0000 2020 NaN NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetData = pd.read_csv(\"../input/ml-tweet/Twitter ML Data.csv\") #Load the dataset into pandas\n",
    "tweetData.head() #Take a peek at the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.484552,
     "end_time": "2022-08-15T20:17:10.297779",
     "exception": false,
     "start_time": "2022-08-15T20:17:09.813227",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.484796,
     "end_time": "2022-08-15T20:17:11.261941",
     "exception": false,
     "start_time": "2022-08-15T20:17:10.777145",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Add column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-15T20:17:12.230893Z",
     "iopub.status.busy": "2022-08-15T20:17:12.230207Z",
     "iopub.status.idle": "2022-08-15T20:17:12.240761Z",
     "shell.execute_reply": "2022-08-15T20:17:12.240204Z",
     "shell.execute_reply.started": "2022-08-12T21:47:24.813918Z"
    },
    "papermill": {
     "duration": 0.497701,
     "end_time": "2022-08-15T20:17:12.240887",
     "exception": false,
     "start_time": "2022-08-15T20:17:11.743186",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweeter</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>TweetLink</th>\n",
       "      <th>TweetTime</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aketaco</td>\n",
       "      <td>RT @odashi_t: 「機械学習がずるをしている（人間が想定しない推論を行う）から良く...</td>\n",
       "      <td>https://twitter.com/187400312/status/127142474...</td>\n",
       "      <td>Fri Jun 12 12:50:56 +0000 2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Atsunov</td>\n",
       "      <td>RT @ML_deep: y = f(x)\\n\\nというモデルで、ひと目では分からぬような関...</td>\n",
       "      <td>https://twitter.com/14404737/status/1271428080...</td>\n",
       "      <td>Fri Jun 12 13:04:10 +0000 2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tweeter                                      OriginalTweet  \\\n",
       "0      NaN                                                NaN   \n",
       "1      NaN                                                NaN   \n",
       "2      NaN                                                NaN   \n",
       "3  aketaco  RT @odashi_t: 「機械学習がずるをしている（人間が想定しない推論を行う）から良く...   \n",
       "4  Atsunov  RT @ML_deep: y = f(x)\\n\\nというモデルで、ひと目では分からぬような関...   \n",
       "\n",
       "                                           TweetLink  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3  https://twitter.com/187400312/status/127142474...   \n",
       "4  https://twitter.com/14404737/status/1271428080...   \n",
       "\n",
       "                        TweetTime   5   6  \n",
       "0                             NaN NaN NaN  \n",
       "1                             NaN NaN NaN  \n",
       "2                             NaN NaN NaN  \n",
       "3  Fri Jun 12 12:50:56 +0000 2020 NaN NaN  \n",
       "4  Fri Jun 12 13:04:10 +0000 2020 NaN NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetData = tweetData.rename(columns = {\"Name\" : \"Tweeter\", \"2\" : \"OriginalTweet\", \"3\" : \"TweetLink\", \"4\" : \"TweetTime\"}) #Changes the column names to something more helpful\n",
    "tweetData.head() #Take a peek at the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.478659,
     "end_time": "2022-08-15T20:17:13.195797",
     "exception": false,
     "start_time": "2022-08-15T20:17:12.717138",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.488027,
     "end_time": "2022-08-15T20:17:14.166490",
     "exception": false,
     "start_time": "2022-08-15T20:17:13.678463",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Check for and remove null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-15T20:17:15.148355Z",
     "iopub.status.busy": "2022-08-15T20:17:15.147276Z",
     "iopub.status.idle": "2022-08-15T20:17:15.159791Z",
     "shell.execute_reply": "2022-08-15T20:17:15.160353Z",
     "shell.execute_reply.started": "2022-08-12T21:47:40.562467Z"
    },
    "papermill": {
     "duration": 0.502185,
     "end_time": "2022-08-15T20:17:15.160517",
     "exception": false,
     "start_time": "2022-08-15T20:17:14.658332",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweeter          1390\n",
      "OriginalTweet    1390\n",
      "TweetLink        1390\n",
      "TweetTime        1390\n",
      "5                   0\n",
      "6                   0\n",
      "dtype: int64\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(tweetData.count()) #Get the counts of values in the dataset\n",
    "\n",
    "#Check each column if there are any null values\n",
    "print(tweetData[\"Tweeter\"].isnull().any())\n",
    "print(tweetData[\"OriginalTweet\"].isnull().any())\n",
    "print(tweetData[\"TweetLink\"].isnull().any())\n",
    "print(tweetData[\"TweetTime\"].isnull().any())\n",
    "print(tweetData[\"5\"].isnull().any())\n",
    "print(tweetData[\"6\"].isnull().any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.476166,
     "end_time": "2022-08-15T20:17:16.111973",
     "exception": false,
     "start_time": "2022-08-15T20:17:15.635807",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "It appears there are no values at all in 5 and 6, so those should be removed entirely. There are also null rows, as shown in the head functions above, so I will just drop those with null tweets and see where to go from there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-15T20:17:17.104716Z",
     "iopub.status.busy": "2022-08-15T20:17:17.103951Z",
     "iopub.status.idle": "2022-08-15T20:17:17.119830Z",
     "shell.execute_reply": "2022-08-15T20:17:17.120521Z",
     "shell.execute_reply.started": "2022-08-12T21:49:15.897307Z"
    },
    "papermill": {
     "duration": 0.520395,
     "end_time": "2022-08-15T20:17:17.120685",
     "exception": false,
     "start_time": "2022-08-15T20:17:16.600290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweeter</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>TweetLink</th>\n",
       "      <th>TweetTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aketaco</td>\n",
       "      <td>RT @odashi_t: 「機械学習がずるをしている（人間が想定しない推論を行う）から良く...</td>\n",
       "      <td>https://twitter.com/187400312/status/127142474...</td>\n",
       "      <td>Fri Jun 12 12:50:56 +0000 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Atsunov</td>\n",
       "      <td>RT @ML_deep: y = f(x)\\n\\nというモデルで、ひと目では分からぬような関...</td>\n",
       "      <td>https://twitter.com/14404737/status/1271428080...</td>\n",
       "      <td>Fri Jun 12 13:04:10 +0000 2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tweeter                                      OriginalTweet  \\\n",
       "0      NaN                                                NaN   \n",
       "1      NaN                                                NaN   \n",
       "2      NaN                                                NaN   \n",
       "3  aketaco  RT @odashi_t: 「機械学習がずるをしている（人間が想定しない推論を行う）から良く...   \n",
       "4  Atsunov  RT @ML_deep: y = f(x)\\n\\nというモデルで、ひと目では分からぬような関...   \n",
       "\n",
       "                                           TweetLink  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3  https://twitter.com/187400312/status/127142474...   \n",
       "4  https://twitter.com/14404737/status/1271428080...   \n",
       "\n",
       "                        TweetTime  \n",
       "0                             NaN  \n",
       "1                             NaN  \n",
       "2                             NaN  \n",
       "3  Fri Jun 12 12:50:56 +0000 2020  \n",
       "4  Fri Jun 12 13:04:10 +0000 2020  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetData = tweetData.drop(columns = [\"5\", \"6\"]) #Drop the null columns\n",
    "tweetData.head() #Take a peek at the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-15T20:17:18.079875Z",
     "iopub.status.busy": "2022-08-15T20:17:18.079124Z",
     "iopub.status.idle": "2022-08-15T20:17:18.109871Z",
     "shell.execute_reply": "2022-08-15T20:17:18.110512Z",
     "shell.execute_reply.started": "2022-08-12T21:49:56.919011Z"
    },
    "papermill": {
     "duration": 0.512899,
     "end_time": "2022-08-15T20:17:18.110672",
     "exception": false,
     "start_time": "2022-08-15T20:17:17.597773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweeter</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>TweetLink</th>\n",
       "      <th>TweetTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aketaco</td>\n",
       "      <td>RT @odashi_t: 「機械学習がずるをしている（人間が想定しない推論を行う）から良く...</td>\n",
       "      <td>https://twitter.com/187400312/status/127142474...</td>\n",
       "      <td>Fri Jun 12 12:50:56 +0000 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Atsunov</td>\n",
       "      <td>RT @ML_deep: y = f(x)\\n\\nというモデルで、ひと目では分からぬような関...</td>\n",
       "      <td>https://twitter.com/14404737/status/1271428080...</td>\n",
       "      <td>Fri Jun 12 13:04:10 +0000 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>arlequin_udon</td>\n",
       "      <td>この話をしていたら\\n「その日記データを機械学習に食わせたら、勝手に日記書きだすんじゃね？」...</td>\n",
       "      <td>https://twitter.com/177861086/status/127142784...</td>\n",
       "      <td>Fri Jun 12 13:03:14 +0000 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>daruchan524</td>\n",
       "      <td>RT @hokuto_sd: JSAI2020の社会データと予測のセッションで、共同研究をし...</td>\n",
       "      <td>https://twitter.com/1879931462/status/12714277...</td>\n",
       "      <td>Fri Jun 12 13:02:41 +0000 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>usdatascientist</td>\n",
       "      <td>RT @unistud_ml: @usdatascientist 購入しました!昨日から見て...</td>\n",
       "      <td>https://twitter.com/1186121103992737792/status...</td>\n",
       "      <td>Fri Jun 12 13:02:24 +0000 2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Tweeter                                      OriginalTweet  \\\n",
       "0          aketaco  RT @odashi_t: 「機械学習がずるをしている（人間が想定しない推論を行う）から良く...   \n",
       "1          Atsunov  RT @ML_deep: y = f(x)\\n\\nというモデルで、ひと目では分からぬような関...   \n",
       "2    arlequin_udon  この話をしていたら\\n「その日記データを機械学習に食わせたら、勝手に日記書きだすんじゃね？」...   \n",
       "3      daruchan524  RT @hokuto_sd: JSAI2020の社会データと予測のセッションで、共同研究をし...   \n",
       "4  usdatascientist  RT @unistud_ml: @usdatascientist 購入しました!昨日から見て...   \n",
       "\n",
       "                                           TweetLink  \\\n",
       "0  https://twitter.com/187400312/status/127142474...   \n",
       "1  https://twitter.com/14404737/status/1271428080...   \n",
       "2  https://twitter.com/177861086/status/127142784...   \n",
       "3  https://twitter.com/1879931462/status/12714277...   \n",
       "4  https://twitter.com/1186121103992737792/status...   \n",
       "\n",
       "                        TweetTime  \n",
       "0  Fri Jun 12 12:50:56 +0000 2020  \n",
       "1  Fri Jun 12 13:04:10 +0000 2020  \n",
       "2  Fri Jun 12 13:03:14 +0000 2020  \n",
       "3  Fri Jun 12 13:02:41 +0000 2020  \n",
       "4  Fri Jun 12 13:02:24 +0000 2020  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetData[\"OriginalTweet\"] = tweetData[\"OriginalTweet\"].apply(lambda x: np.nan if not x else x) #Change blank tweets to null as well\n",
    "tweetData.dropna(subset = [\"OriginalTweet\"], inplace = True) #Drop the nulls based on the tweet data\n",
    "tweetData.reset_index(drop=True, inplace=True) #Reset the index for later looping\n",
    "tweetData.head() #Take a peek at the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-15T20:17:19.065617Z",
     "iopub.status.busy": "2022-08-15T20:17:19.064925Z",
     "iopub.status.idle": "2022-08-15T20:17:19.075814Z",
     "shell.execute_reply": "2022-08-15T20:17:19.074605Z",
     "shell.execute_reply.started": "2022-08-12T21:50:00.812681Z"
    },
    "papermill": {
     "duration": 0.489824,
     "end_time": "2022-08-15T20:17:19.076005",
     "exception": false,
     "start_time": "2022-08-15T20:17:18.586181",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "#Check each column if there are any null values\n",
    "print(tweetData[\"Tweeter\"].isnull().any())\n",
    "print(tweetData[\"OriginalTweet\"].isnull().any())\n",
    "print(tweetData[\"TweetLink\"].isnull().any())\n",
    "print(tweetData[\"TweetTime\"].isnull().any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.475834,
     "end_time": "2022-08-15T20:17:20.034596",
     "exception": false,
     "start_time": "2022-08-15T20:17:19.558762",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "That took out all the null values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.475564,
     "end_time": "2022-08-15T20:17:20.989975",
     "exception": false,
     "start_time": "2022-08-15T20:17:20.514411",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.473942,
     "end_time": "2022-08-15T20:17:21.942428",
     "exception": false,
     "start_time": "2022-08-15T20:17:21.468486",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Tweet cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-15T20:17:22.897930Z",
     "iopub.status.busy": "2022-08-15T20:17:22.896827Z",
     "iopub.status.idle": "2022-08-15T20:17:24.641015Z",
     "shell.execute_reply": "2022-08-15T20:17:24.640069Z",
     "shell.execute_reply.started": "2022-08-12T21:50:39.288272Z"
    },
    "papermill": {
     "duration": 2.220622,
     "end_time": "2022-08-15T20:17:24.641166",
     "exception": false,
     "start_time": "2022-08-15T20:17:22.420544",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @hokuto_sd: JSAI2020の社会データと予測のセッションで、共同研究をしている桑田和さんが「機械学習アプローチに基づく中古ファッションアイテムの価格保持期間の適正化モデルの提案」というタイトルで発表しました！\n",
      "#JSAI2020 \n",
      "https://t.co/… \n",
      " \n",
      "      jsai 社会 データ 予測 セッション 共同 研究 桑田 和 機械 学習 アプローチ 基づく 中古 ファッション アイテム 価格 保持 期間 適正 化 モデル 提案 タイトル 発表 まし jsai     \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweeter</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>TweetLink</th>\n",
       "      <th>TweetTime</th>\n",
       "      <th>CleanTweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aketaco</td>\n",
       "      <td>RT @odashi_t: 「機械学習がずるをしている（人間が想定しない推論を行う）から良く...</td>\n",
       "      <td>https://twitter.com/187400312/status/127142474...</td>\n",
       "      <td>Fri Jun 12 12:50:56 +0000 2020</td>\n",
       "      <td>機械 学習 ずる 人間 想定 推論 行う 良く 思う 人 人間 理解 推論 行う ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Atsunov</td>\n",
       "      <td>RT @ML_deep: y = f(x)\\n\\nというモデルで、ひと目では分からぬような関...</td>\n",
       "      <td>https://twitter.com/14404737/status/1271428080...</td>\n",
       "      <td>Fri Jun 12 13:04:10 +0000 2020</td>\n",
       "      <td>y = fx   モデル ひと目 分から 関係 性 大量 y x 求めよう 機械 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>arlequin_udon</td>\n",
       "      <td>この話をしていたら\\n「その日記データを機械学習に食わせたら、勝手に日記書きだすんじゃね？」...</td>\n",
       "      <td>https://twitter.com/177861086/status/127142784...</td>\n",
       "      <td>Fri Jun 12 13:03:14 +0000 2020</td>\n",
       "      <td>話 日記 データ 機械 学習 食わ 勝手に 日記 書き だす じゃ って 言わ 笑っ なに ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>daruchan524</td>\n",
       "      <td>RT @hokuto_sd: JSAI2020の社会データと予測のセッションで、共同研究をし...</td>\n",
       "      <td>https://twitter.com/1879931462/status/12714277...</td>\n",
       "      <td>Fri Jun 12 13:02:41 +0000 2020</td>\n",
       "      <td>jsai 社会 データ 予測 セッション 共同 研究 桑田 和 機械 学習 アプロ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>usdatascientist</td>\n",
       "      <td>RT @unistud_ml: @usdatascientist 購入しました!昨日から見て...</td>\n",
       "      <td>https://twitter.com/1186121103992737792/status...</td>\n",
       "      <td>Fri Jun 12 13:02:24 +0000 2020</td>\n",
       "      <td>購入 まし 昨日 見 すごく わかり やすい 機械 学習 使える 頑張っ 勉強</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Tweeter                                      OriginalTweet  \\\n",
       "0          aketaco  RT @odashi_t: 「機械学習がずるをしている（人間が想定しない推論を行う）から良く...   \n",
       "1          Atsunov  RT @ML_deep: y = f(x)\\n\\nというモデルで、ひと目では分からぬような関...   \n",
       "2    arlequin_udon  この話をしていたら\\n「その日記データを機械学習に食わせたら、勝手に日記書きだすんじゃね？」...   \n",
       "3      daruchan524  RT @hokuto_sd: JSAI2020の社会データと予測のセッションで、共同研究をし...   \n",
       "4  usdatascientist  RT @unistud_ml: @usdatascientist 購入しました!昨日から見て...   \n",
       "\n",
       "                                           TweetLink  \\\n",
       "0  https://twitter.com/187400312/status/127142474...   \n",
       "1  https://twitter.com/14404737/status/1271428080...   \n",
       "2  https://twitter.com/177861086/status/127142784...   \n",
       "3  https://twitter.com/1879931462/status/12714277...   \n",
       "4  https://twitter.com/1186121103992737792/status...   \n",
       "\n",
       "                        TweetTime  \\\n",
       "0  Fri Jun 12 12:50:56 +0000 2020   \n",
       "1  Fri Jun 12 13:04:10 +0000 2020   \n",
       "2  Fri Jun 12 13:03:14 +0000 2020   \n",
       "3  Fri Jun 12 13:02:41 +0000 2020   \n",
       "4  Fri Jun 12 13:02:24 +0000 2020   \n",
       "\n",
       "                                          CleanTweet  \n",
       "0       機械 学習 ずる 人間 想定 推論 行う 良く 思う 人 人間 理解 推論 行う ...  \n",
       "1       y = fx   モデル ひと目 分から 関係 性 大量 y x 求めよう 機械 ...  \n",
       "2  話 日記 データ 機械 学習 食わ 勝手に 日記 書き だす じゃ って 言わ 笑っ なに ...  \n",
       "3       jsai 社会 データ 予測 セッション 共同 研究 桑田 和 機械 学習 アプロ...  \n",
       "4           購入 まし 昨日 見 すごく わかり やすい 機械 学習 使える 頑張っ 勉強   "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Modified from my previous nlp project: https://www.kaggle.com/lunamcbride24/coronavirus-tweet-processing\n",
    "\n",
    "punctuations = \"\"\"!()（）「」、-!！[]{};:+'\"\\,<>./?@#$%^&*_~Â。…・，【】？\"\"\" #List of punctuations to remove, including a weird A that will not process out any other way\n",
    "\n",
    "stopwords = spacy.lang.ja.stop_words.STOP_WORDS\n",
    "\n",
    "#CleanTweets: parces the tweets and removes punctuation, stop words, digits, and links.\n",
    "#Input: the list of tweets that need parsing\n",
    "#Output: the parsed tweets\n",
    "def cleanTweets(tweetParse):\n",
    "    for i in range(0,len(tweetParse)):\n",
    "        tweet = tweetParse[i] #Putting the tweet into a variable so that it is not calling tweetParse[i] over and over\n",
    "        tweet = html.unescape(tweet) #Removes leftover HTML elements, such as &amp;\n",
    "        tweet = re.sub(r\"RT\", ' ', tweet)\n",
    "        tweet = re.sub(r\"\\n\", ' ', tweet)\n",
    "        tweet = re.sub(r\"@\\w+\", ' ', tweet) #Completely removes @'s, as other peoples' usernames mean nothing\n",
    "        tweet = re.sub(r'https\\S+', ' ', tweet) #Removes links, as links provide no data in tweet analysis in themselves\n",
    "        tweet = re.sub(r\"\\d+\", ' ', tweet) #Removes numbers, as well as cases like the \"th\" in \"14th\"\n",
    "        tweet = ''.join([punc for punc in tweet if not punc in punctuations]) #Removes the punctuation defined above\n",
    "        tweet = tweet.lower() #Turning the tweets lowercase real quick for later use\n",
    "    \n",
    "        tweetWord = nlp.tokenizer(tweet) #Splits the tweet into individual words\n",
    "        tweetParse[i] = ''.join([word.orth_ + \" \" for word in tweetWord if word.is_stop == False]) #Checks if the words are stop words\n",
    "       \n",
    "        \n",
    "    return tweetParse #Returns the parsed tweets\n",
    "\n",
    "tweets = tweetData[\"OriginalTweet\"].copy() #Gets a copy of the tweets to send to the function call\n",
    "tweetData[\"CleanTweet\"] = cleanTweets(tweets) #Adds a CleanTweet column and fills it with processed tweets\n",
    "print(tweetData[\"OriginalTweet\"][3], \"\\n \\n\", tweetData[\"CleanTweet\"][3]) #Prints an example sentence\n",
    "tweetData.head() #Takes a peek at the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.476002,
     "end_time": "2022-08-15T20:17:25.597378",
     "exception": false,
     "start_time": "2022-08-15T20:17:25.121376",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.476228,
     "end_time": "2022-08-15T20:17:26.546982",
     "exception": false,
     "start_time": "2022-08-15T20:17:26.070754",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Japanese Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-15T20:17:27.509029Z",
     "iopub.status.busy": "2022-08-15T20:17:27.508284Z",
     "iopub.status.idle": "2022-08-15T20:17:27.514267Z",
     "shell.execute_reply": "2022-08-15T20:17:27.514782Z",
     "shell.execute_reply.started": "2022-08-12T21:50:47.927160Z"
    },
    "papermill": {
     "duration": 0.488778,
     "end_time": "2022-08-15T20:17:27.514966",
     "exception": false,
     "start_time": "2022-08-15T20:17:27.026188",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ち', 'だっ', 'よ', 'たら', 'はじめ', 'うち', 'いく', 'で', 'とき', 'いい', 'いわ', 'あ', 'よっ', 'それ', 'ね', 'さ', 'くる', 'お', 'いつ', 'は', 'しよう', 'よれ', 'なし', 'など', 'もの', 'なく', 'たち', 'よう', 'より', 'い', 'および', 'とっ', 'やっ', 'ある', 'え', 'ま', 'き', 'ほか', 'のち', 'かけ', 'とも', 'この', 'そこ', 'できる', 'られる', 'なる', 'よる', 'なけれ', 'から', 'です', 'ながら', 'み', 'しまっ', 'ため', 'そう', 'な', 'ほとんど', 'が', '一', 'くん', 'ほど', 'た', 'あまり', 'もう', 'し', 'べき', 'ら', 'ちゃん', 'ず', 'ぶり', 'かつて', 'や', 'ます', 'その', 'もっ', 'せい', 'おり', 'か', 'て', 'いる', 'れる', 'つい', 'れ', 'おけ', 'つけ', 'と', 'しかし', 'たり', 'せ', 'ほぼ', 'おら', 'さん', 'なお', 'こと', 'たい', 'さらに', 'にて', 'なり', 'つ', 'よく', 'ば', 'ところ', 'す', 'どう', 'ここ', 'しか', 'でき', 'だ', 'せる', 'らしい', 'ひと', 'あり', 'ん', 'を', 'いう', 'かつ', 'そして', 'それぞれ', 'る', 'ただし', 'に', 'なら', 'だけ', 'ご', 'ごと', 'また', 'もと', 'しまう', 'の', 'する', 'おい', 'こう', 'なかっ', 'あっ', 'まま', 'こ', 'いずれ', 'すべて', 'きっかけ', 'かなり', 'も', 'あれ', 'いっ', 'られ', 'へ', 'これ', 'まで', 'すぐ', 'ない', 'のみ', 'つつ', 'あるいは', 'ぬ', 'なっ']\n"
     ]
    }
   ],
   "source": [
    "print(list(stopwords)) #Print the stopwords for reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.475764,
     "end_time": "2022-08-15T20:17:28.487986",
     "exception": false,
     "start_time": "2022-08-15T20:17:28.012222",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.479125,
     "end_time": "2022-08-15T20:17:29.444047",
     "exception": false,
     "start_time": "2022-08-15T20:17:28.964922",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Get word counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.474823,
     "end_time": "2022-08-15T20:17:30.394988",
     "exception": false,
     "start_time": "2022-08-15T20:17:29.920165",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Quick source list: https://www.geeksforgeeks.org/python-get-first-n-keyvalue-pairs-in-given-dictionary/ , https://www.w3resource.com/python-exercises/dictionary/python-data-type-dictionary-exercise-1.php "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-15T20:17:31.376411Z",
     "iopub.status.busy": "2022-08-15T20:17:31.374325Z",
     "iopub.status.idle": "2022-08-15T20:17:31.380819Z",
     "shell.execute_reply": "2022-08-15T20:17:31.380047Z"
    },
    "papermill": {
     "duration": 0.511572,
     "end_time": "2022-08-15T20:17:31.381001",
     "exception": false,
     "start_time": "2022-08-15T20:17:30.869429",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'学習': 1783, '機械': 1589, 'ai': 243, 'データ': 235, '的': 223, 'けど': 210, 'python': 193, '中国': 188, 'てる': 178, '性': 163, '人': 161, '世界': 156, '人工': 148, '知能': 147, 'って': 145, '第': 140, '可能': 139, '年': 133, 'プログラミング': 129, '次': 126}\n"
     ]
    }
   ],
   "source": [
    "tweets = tweetData[\"CleanTweet\"].copy() #Copy the clean tweets for processing\n",
    "count = dict() #Creates a dictionary \n",
    "for i in range(0,len(tweets)):\n",
    "    words = tweets[i].split()\n",
    "    for word in words:\n",
    "        if word in count:\n",
    "            count[word] += 1\n",
    "        else:\n",
    "            count[word] = 1\n",
    "\n",
    "sortCount = {word : summ for word, summ in sorted(count.items(), key=operator.itemgetter(1),reverse=True)}\n",
    "print(dict(list(sortCount.items())[0: 20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.48521,
     "end_time": "2022-08-15T20:17:32.343199",
     "exception": false,
     "start_time": "2022-08-15T20:17:31.857989",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Interestingly, there are several top options here that I would consider stopwords, but are not in the stopwords list. For example, けど, which means but, but is also used in sentences to imply another sentence (which is not something a machine can likely pick up on). The other words I would consider stopwords in the top 20 would be 的, てる, って, 第, and 次."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.481608,
     "end_time": "2022-08-15T20:17:33.346895",
     "exception": false,
     "start_time": "2022-08-15T20:17:32.865287",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.478105,
     "end_time": "2022-08-15T20:17:34.305059",
     "exception": false,
     "start_time": "2022-08-15T20:17:33.826954",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Matplotlib Japanese Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-15T20:17:35.270565Z",
     "iopub.status.busy": "2022-08-15T20:17:35.269709Z",
     "iopub.status.idle": "2022-08-15T20:17:35.586602Z",
     "shell.execute_reply": "2022-08-15T20:17:35.585714Z"
    },
    "papermill": {
     "duration": 0.803371,
     "end_time": "2022-08-15T20:17:35.586790",
     "exception": false,
     "start_time": "2022-08-15T20:17:34.783419",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 20 artists>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 23398 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 32722 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 27231 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 26800 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 12487 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 12540 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 12479 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 30340 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 12369 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 12393 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 20013 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 22269 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 12390 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 12427 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 24615 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 20154 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 19990 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 30028 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 24037 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 30693 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 33021 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 12387 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 31532 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 21487 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 24180 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 12503 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 12525 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 12464 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 12521 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 12511 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 12531 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 27425 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 23398 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 32722 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 27231 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 26800 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 12487 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 12540 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 12479 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 30340 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 12369 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 12393 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 20013 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 22269 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 12390 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 12427 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 24615 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 20154 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 19990 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 30028 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 24037 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 30693 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 33021 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 12387 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 31532 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 21487 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 24180 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 12503 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 12525 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 12464 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 12521 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 12511 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 12531 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 27425 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "top = dict(list(sortCount.items())[0: 20])\n",
    "fig, axes = plt.subplots(nrows = 1, ncols = 1, figsize=(16,8))\n",
    "plt.bar(top.keys(), top.values(), color = \"g\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.486286,
     "end_time": "2022-08-15T20:17:36.556676",
     "exception": false,
     "start_time": "2022-08-15T20:17:36.070390",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "As I sort of expected, Matplotlib does not recognize Japanese characters. It is the whole reason I wanted to test this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.47967,
     "end_time": "2022-08-15T20:17:37.522214",
     "exception": false,
     "start_time": "2022-08-15T20:17:37.042544",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.484145,
     "end_time": "2022-08-15T20:17:38.534287",
     "exception": false,
     "start_time": "2022-08-15T20:17:38.050142",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.485266,
     "end_time": "2022-08-15T20:17:39.518448",
     "exception": false,
     "start_time": "2022-08-15T20:17:39.033182",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The spacy Japanese is pretty strong. Of course, I tried NLTK Japanese and could not get it to work at all, so at the very least, getting spacy up and working is pretty big. In terms of processing, Japanese is considered a big, single block by functions like split(). This thus requires tokenizing followed by getting the individual word out in order to actually process the text. And even when tokenized, words like 機械学習 (Machine Learning) that are made of two words are split into the two words, which is something to look out for. English may have concepts like this that are two words like machine learning, but Japanese words like this this often hold more meaning together than as the sum of their parts. \n",
    "\n",
    "This is followed by a check with the stopwords, which does not include some words that I would consider stopwords, so that is another thing to look out for when processing Japanese. One more key part of this is matplotlib, as it does not recognize Japanese characters at all. It just leaves boxes in the place of a character. This means numeric data like model accuracy hold a lot more value when working with Japanese than categorical data that would typically be powerful during exploration. \n",
    "\n",
    "As for the dataset itself, it is pretty barebones. It is machine learning, so the most common words (besides those I would consider stopwords), are expectedly machine, learning, AI, programming, and python. There are also words like ability (可能) and world (世界), so likely some optimistic discussion on changing the world and learning ability, similar to how it is discussed in English. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 230.826497,
   "end_time": "2022-08-15T20:17:40.105497",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-08-15T20:13:49.279000",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
